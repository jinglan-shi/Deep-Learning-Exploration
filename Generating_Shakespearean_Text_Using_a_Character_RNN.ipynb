{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Shakespearean Text Using a Character RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is an NLP modeling exercise (**Char-RNN**) followed the instruction of [*Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow*](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) on topic **Natural Language Processing with RNNs and Attention**."
      ],
      "metadata": {
        "id": "Hgtc9TvoM9if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "TRVgxG5NQCxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the training dataset"
      ],
      "metadata": {
        "id": "QYSVF50NPdAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Shakespeare's work"
      ],
      "metadata": {
        "id": "-5K8yrYwP2E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "filepath = tf.keras.utils.get_file('shakespeare.txt', shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "  shakespeare_txt = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmrBTLP_QQIX",
        "outputId": "dd42c7a3-000e-404c-cf71-4a4129177d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode every character as an interger"
      ],
      "metadata": {
        "id": "iSW614swWJbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode on character level\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts([shakespeare_txt])"
      ],
      "metadata": {
        "id": "UfnXujZfWLca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check word_index map dictionary\n",
        "word_index=tokenizer.word_index\n",
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngh9JrzyZArm",
        "outputId": "f78801ed-c2d2-47b4-fed2-736000a711bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 11,\n",
              " ' ': 1,\n",
              " '!': 31,\n",
              " '$': 39,\n",
              " '&': 38,\n",
              " \"'\": 28,\n",
              " ',': 18,\n",
              " '-': 32,\n",
              " '.': 27,\n",
              " '3': 37,\n",
              " ':': 24,\n",
              " ';': 29,\n",
              " '?': 30,\n",
              " 'a': 5,\n",
              " 'b': 22,\n",
              " 'c': 19,\n",
              " 'd': 13,\n",
              " 'e': 2,\n",
              " 'f': 20,\n",
              " 'g': 21,\n",
              " 'h': 7,\n",
              " 'i': 6,\n",
              " 'j': 33,\n",
              " 'k': 25,\n",
              " 'l': 12,\n",
              " 'm': 15,\n",
              " 'n': 10,\n",
              " 'o': 4,\n",
              " 'p': 23,\n",
              " 'q': 34,\n",
              " 'r': 9,\n",
              " 's': 8,\n",
              " 't': 3,\n",
              " 'u': 14,\n",
              " 'v': 26,\n",
              " 'w': 17,\n",
              " 'x': 35,\n",
              " 'y': 16,\n",
              " 'z': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of unique character IDs\n",
        "max_id = len(tokenizer.word_index)\n",
        "max_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XLVWhBydXLt",
        "outputId": "5f77d9dc-8e53-4ee9-9322-5e4383e2bd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on a sample\n",
        "sample = 'First'\n",
        "encoded_sample = tokenizer.texts_to_sequences([sample])\n",
        "encoded_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLuSrtDiXgqf",
        "outputId": "95fe5895-e404-4caf-9449-c9617bed5b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sample = tokenizer.sequences_to_texts(encoded_sample)\n",
        "decoded_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4RrWQGXnhW",
        "outputId": "4336ebc6-e459-435e-ede8-2f9d45cd8730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the whole text\n",
        "[encoded_text] = np.array(tokenizer.texts_to_sequences([shakespeare_txt])) - 1\n",
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL1VBFJQdT6L",
        "outputId": "2b5700b4-0cf1-4403-d99a-4bd6c50c94ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19,  5,  8, ..., 20, 26, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split sequential dataset"
      ],
      "metadata": {
        "id": "V57vaLANd2JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "dataset_size = len(encoded_text)\n",
        "split_size = int(dataset_size * 0.9)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(encoded_text[:split_size])\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(encoded_text[split_size:])\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJLs3jqDeJ7U",
        "outputId": "8496f474-836e-4682-9618-57e61fb3884a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>,\n",
              " <TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chop sequential dataset into windows"
      ],
      "metadata": {
        "id": "r10-dW7-fU2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_STEPS = 100\n",
        "SHIFT = 1\n",
        "\n",
        "window_length = N_STEPS + SHIFT\n",
        "train_dataset = train_dataset.window(window_length, shift=SHIFT, drop_remainder=True)\n",
        "test_dataset = test_dataset.window(window_length, shift=SHIFT, drop_remainder=True)\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0AAY4scf-QT",
        "outputId": "b8d1ad3c-88f3-46b1-e705-30c892e55d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<WindowDataset element_spec=DatasetSpec(TensorSpec(shape=(), dtype=tf.int64, name=None), TensorShape([]))>,\n",
              " <WindowDataset element_spec=DatasetSpec(TensorSpec(shape=(), dtype=tf.int64, name=None), TensorShape([]))>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert nested dataset into flat dataset\n",
        "train_dataset = train_dataset.flat_map(lambda x: x.batch(window_length))\n",
        "test_dataset = test_dataset.flat_map(lambda x: x.batch(window_length))"
      ],
      "metadata": {
        "id": "6qcDEUJ9hCiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process dataset into features and labels\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(10000).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x: (x[:, :-1], x[:, 1:]))\n",
        "test_dataset = test_dataset.map(lambda x: (x[:, :-1], x[:, 1:]))\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwi-Ch7kSvt",
        "outputId": "ec8f4cda-08cc-44d8-d017-fbc63bd5e879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<MapDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>,\n",
              " <MapDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode features\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.one_hot(x, depth=max_id), y))\n",
        "test_dataset = test_dataset.map(lambda x, y: (tf.one_hot(x, depth=max_id), y))\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdhRKnsqlngq",
        "outputId": "e060b844-4cd3-4399-8e10-785cebc3de38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<MapDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>,\n",
              " <MapDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure for better performance\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0Xpg2hNmBI_",
        "outputId": "db2e53ea-b68f-4aa5-839e-d55dde69fd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>,\n",
              " <PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a view of the processed dataset\n",
        "for X_batch, Y_batch in train_dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_g8EETG4V3f",
        "outputId": "8a2bc281-d698-43d7-8a14-252b70e969d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 39) (32, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded_text)/32 *0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A9wrCJO4b8O",
        "outputId": "aad2c520-f3af-47d6-de60-016ac7ce64bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3485.6062500000003"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Built and train Char-RNN model"
      ],
      "metadata": {
        "id": "QZmJ_ZxSm8nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct model\n",
        "model = tf.keras.Sequential([layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\n",
        "                             layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "                             layers.TimeDistributed(layers.Dense(max_id, activation='softmax'))])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit model \n",
        "# (due to the large size of dataset and limited computaion power of my hardware, only a small portion of sataset is used in fitting process)\n",
        "history = model.fit(train_dataset,\n",
        "                   steps_per_epoch=100,\n",
        "                   epochs=20,\n",
        "                   validation_data=test_dataset,\n",
        "                   validation_steps=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3raSpMISnHHJ",
        "outputId": "f101d7e8-5237-41a2-b11e-3867b5a37bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 58s 506ms/step - loss: 2.9714 - accuracy: 0.1882 - val_loss: 2.6626 - val_accuracy: 0.2330\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 52s 518ms/step - loss: 2.4388 - accuracy: 0.3010 - val_loss: 2.4758 - val_accuracy: 0.2789\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 2.3219 - accuracy: 0.3241 - val_loss: 2.3678 - val_accuracy: 0.2992\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 50s 499ms/step - loss: 2.1737 - accuracy: 0.3590 - val_loss: 2.2933 - val_accuracy: 0.3234\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 2.0634 - accuracy: 0.3887 - val_loss: 2.2516 - val_accuracy: 0.3339\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 1.9817 - accuracy: 0.4067 - val_loss: 2.2128 - val_accuracy: 0.3507\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 50s 499ms/step - loss: 1.9236 - accuracy: 0.4213 - val_loss: 2.1915 - val_accuracy: 0.3621\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 50s 499ms/step - loss: 1.8885 - accuracy: 0.4322 - val_loss: 2.1807 - val_accuracy: 0.3610\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 50s 499ms/step - loss: 1.8519 - accuracy: 0.4437 - val_loss: 2.1446 - val_accuracy: 0.3754\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 1.8340 - accuracy: 0.4474 - val_loss: 2.1350 - val_accuracy: 0.3852\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 1.7923 - accuracy: 0.4590 - val_loss: 2.1302 - val_accuracy: 0.3850\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 1.7740 - accuracy: 0.4619 - val_loss: 2.1384 - val_accuracy: 0.3793\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 1.7332 - accuracy: 0.4724 - val_loss: 2.1477 - val_accuracy: 0.3801\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 1.7146 - accuracy: 0.4757 - val_loss: 2.1749 - val_accuracy: 0.3863\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 1.6766 - accuracy: 0.4851 - val_loss: 2.1894 - val_accuracy: 0.3897\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 1.6307 - accuracy: 0.5017 - val_loss: 2.1678 - val_accuracy: 0.3923\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 1.5885 - accuracy: 0.5164 - val_loss: 2.1701 - val_accuracy: 0.3755\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 50s 498ms/step - loss: 1.5944 - accuracy: 0.5110 - val_loss: 2.1616 - val_accuracy: 0.3791\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 1.5749 - accuracy: 0.5179 - val_loss: 2.1618 - val_accuracy: 0.3921\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 1.5657 - accuracy: 0.5217 - val_loss: 2.1525 - val_accuracy: 0.3911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the trained model to predict"
      ],
      "metadata": {
        "id": "ZdbnTLoLsDMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to preprocess text\n",
        "def preprocess(text):\n",
        "  X = np.array(tokenizer.texts_to_sequences(text)) - 1\n",
        "  return tf.one_hot(X, max_id)"
      ],
      "metadata": {
        "id": "o0funKXlKCyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the next letter\n",
        "X_encoded = preprocess(['How are yo'])\n",
        "y_pred = model.predict(X_encoded)\n",
        "y_pred = y_pred[0].argmax(axis=1)\n",
        "y_pred_decoded = tokenizer.sequences_to_texts(np.expand_dims(y_pred, axis=0) + 1)[0][-1]\n",
        "y_pred_decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YiYgIi_2Kwyt",
        "outputId": "fc3d74e3-8d92-4151-9052-e9ebff3bdc1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate fake Shakespeare text"
      ],
      "metadata": {
        "id": "9ZYyzhDQiZ3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to pick the next character randomly\n",
        "def next_char(text, temperature):\n",
        "  X_encoded = preprocess([text])\n",
        "  y_proba = model.predict(X_encoded)[0,-1:,:]\n",
        "  rescaled_logits = tf.math.log(y_proba)/temperature\n",
        "  char_id = tf.random.categorical(rescaled_logits, num_samples=1)+1\n",
        "  return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "metadata": {
        "id": "0H7b3_Uait1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a function to generate characters consecutively\n",
        "def complete_text(text, n_chars, temperature=1):\n",
        "  for _ in range(n_chars):\n",
        "    text += next_char(text, temperature)\n",
        "  return text"
      ],
      "metadata": {
        "id": "4zg_A3F6kmjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text the model's predictive power\n",
        "print(complete_text('She is ugl', n_chars=50, temperature=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-C5Bix3lJs0",
        "outputId": "489bd285-41d7-40e9-d241-134b391dcf3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She is ugle eser to preantly,\n",
            "a pereifure an canure number f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text('A pig is flying w', n_chars=50, temperature=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmvG4kBYlTfW",
        "outputId": "5388aefa-0524-43ca-97dd-17f710a88756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A pig is flying witjenkat; quusproces and veigre.\n",
            "\n",
            "all cmxic? you,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text('A pig is flying w', n_chars=50, temperature=0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYLT_vjslhfZ",
        "outputId": "0c9808df-76a7-46e6-8940-1a517b5a62b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A pig is flying were such of the people,\n",
            "the people, the people, an\n"
          ]
        }
      ]
    }
  ]
}